## 추정통계란?
1) 추정: 점추정 (모평균을 70.4점 이렇게 하나의 값으로 추정하는 것) / 구간추정 (신뢰구간을 두어 추정하는 것)
2) 검정: 모집단의 통계적 성질에 대해 가설을 세우고 그 가설이 옳은지 여부를 판단하는 기법

   ex. 주사위가 일반적인 주사위인지 여부를 확인하고 싶을 때, 주사위가 일반적인 주사위라는 가설을 세우고, 그가설이 옳은지 여부를 통계학적으로 판정.



### 1. 1차원 이산형 확률변수

### 1.1 1차원 이상형 확률변수의 정의
- 확률질량함수 or 확률함수 PMF (probability mass function): 이산 확률변수 X에 관한 함수를 만드는 것

<img width="187" alt="스크린샷 2023-08-05 오후 7 10 55" src="https://github.com/hozyhozy/Statistics/assets/123252821/3bb318fb-3483-4643-9b7d-97c89b683b3e">

> f(x) = P(X=x)


``` python
#함수로 구현하면
def f(x):
   if x in x_set:
      return x/21
   else:
      return 0

# 확률 p_k를 구한다
prob = np.array([f(x_k) for x_k in x_set])

# x_k와 p_k의 대응을 사전식으로 표시
dict(zip(x_set, prob))

#결과값
{1: 0.047619047619047616,
 2: 0.09523809523809523,
 3: 0.14285714285714285,
 4: 0.19047619047619047,
 5: 0.23809523809523808,
 6: 0.2857142857142857}

#그래프를 그림으로써 시각적으로 이해할 수 있음
fig = plt.figure(figsize=(10, 6))
ax = fig.add_subplot(111)
ax.bar(x_set, prob)
ax.set_xlabel('value')
ax.set_ylabel('probability')

plt.show()
```


### 1.2 확률의 성질

1. 확률은 절대적으로 0보다 크다
2. 모든 확률을 더하면 1이다

- $f(x_k) >= 0$
- $\sum_{k}f(x_k) = 1$


``` python
np.all(prob>=0) # 모든 요소가 참일때 참을 반환하는 함수
np.sum(prob) # 합이 1이되는지 확인
```


### 1.3 누적분포함수

- $F(x)=P(X<=x)=\sum_{x_k<=x}f(x_k)$

``` python
def F(X):
   return np.sum([f(x_k) for x_k in x_set if x_k <=x])
```

### 1.4 확률변수의 변환
- 만약 주사위 확률변수에 2X+3을 한다면, {1,2,3,4,5,6} --> {5,7,9,11,13,15}로 변환됨 (이또한 확률변수)

```python
y_set = np.array([2 * x_k + 3 for x_k in x_set])
prob = np.array([f(x_k) for x_k in x_set])
dict(zip(y_set, prob))

# 결과값
{5: 0.047619047619047616,
 7: 0.09523809523809523,
 9: 0.14285714285714285,
 11: 0.19047619047619047,
 13: 0.23809523809523808,
 15: 0.2857142857142857}
```

### 2. 1차원 이산형 확률변수의 지표
1) 기댓값
2) 분산

### 2.1 기댓값 ($\mu$(뮤), $E(X)$)

- $E(x)=\sum_{k}x_k * f(x_k)$

``` python
# 평균 구하기
np.sum([x_k * f(x_k) for x_k in x_set])

# 결과값
4.333

# 100만번 시행한다면
sample = np.random.choice(x_set, int(1e6), p = prob)
np.mean(sample)

# 결과값
4.333
```

**변환한 확률변수 계산**
- $E(g(X)) = \sum_{k}g(x_k)*f(x_k)$
- ex. $E(Y)=E(2X+3)=\sum_{k}(2x_k+3) * f(x_k)$


``` python
X= [x_set, f] #f는 function

def E(X, g= lambda x: x):
   x_set, f= X
return np.sum([g(x_k)*f(x_k) for x_k in x_set])

E(X, g=lambda x: 2*x + 3)

# 결과값
11.667
```

**기댓값에는 선형성 성질이 있다**
- a,b를 실수, X를 확률변수로 했을때
- $E(aX+b)=aE(X)+b$ 가 성립한다


### 2.2 분산
확률변수의 분산도 데이터의 분산과 마찬가지로 산포도를 나타내는 지표
- $V(X)=\sum_{k}(x_k-\mu)^2 * f(x_k)$
- $\sigma^2$ 으로 표기한다 or $V(X)$

``` python
mean = E(X)
np.sum([x_k-mean)**2*f(x_k) for x_k in x_set])
```


**변환한 확륣변수 계산**
- $V(g(X))=\sum_{k}(g(x_k)-E(g(X)))^2 * f(x_k)

  
``` python
def V(X, g=lambda x:x):
   x_set, f = X
   mean = E(X, g)
   return np.sum([g(x_k)-mean)**2 * f(x_k) for x_k in x_set])

V(x, lambda x: 2*x+3)
```
  
- 또는 $V(aX+b)=a^2*V(X)$

``` python
2**2 * V(X)
```
